{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75fa50c2-c6ad-4a1c-92e1-7f36ddb87541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-27 20:16:46.196344: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-27 20:16:46.196564: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-27 20:16:46.230918: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-27 20:16:47.216961: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-27 20:16:47.217187: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28)\n",
      "y_train shape: (60000,)\n",
      "x_test shape: (10000, 28, 28)\n",
      "y_test shape: (10000,)\n",
      "X shape: (784, 60000), Y shape: (60000,)\n",
      "Xtest shape: (784, 10000), Ytest shape: (10000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-27 20:16:48.559289: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2025-10-27 20:16:48.599784: E tensorflow/core/util/util.cc:131] oneDNN supports DT_UINT8 only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden: 10, Output: 10, LR: 0.01, Epochs: 1000\n",
      "(10, 784) (10, 1) (10, 10) (10, 1)\n",
      "Epoch    1 | Loss: 2.323879 | Accuracy: 14.35%\n",
      "Epoch  100 | Loss: 1.841864 | Accuracy: 42.58%\n",
      "Epoch  200 | Loss: 1.474966 | Accuracy: 60.95%\n",
      "Epoch  300 | Loss: 1.197330 | Accuracy: 72.13%\n",
      "Epoch  400 | Loss: 1.004761 | Accuracy: 76.65%\n",
      "Epoch  500 | Loss: 0.875591 | Accuracy: 79.06%\n",
      "Epoch  600 | Loss: 0.783946 | Accuracy: 80.77%\n",
      "Epoch  700 | Loss: 0.715533 | Accuracy: 82.14%\n",
      "Epoch  800 | Loss: 0.662518 | Accuracy: 83.38%\n",
      "Epoch  900 | Loss: 0.620251 | Accuracy: 84.21%\n",
      "Epoch 1000 | Loss: 0.585816 | Accuracy: 84.98%\n",
      "Epoch    0 | Cost: 0.693175\n",
      "Epoch  100 | Cost: 0.685252\n",
      "Epoch  200 | Cost: 0.680434\n",
      "Epoch  300 | Cost: 0.677484\n",
      "Epoch  400 | Cost: 0.675651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devika/Desktop/DataScience_Lab/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Keras model for comparison...\n",
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9274 - loss: 0.2453\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9677 - loss: 0.1060\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9767 - loss: 0.0744\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9816 - loss: 0.0567\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9856 - loss: 0.0445\n",
      "\n",
      "✅ Test Accuracy (Keras Model): 97.58%\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------\n",
    "# Assignment 4: Implementing FCNN from Scratch using TensorFlow\n",
    "# -------------------------------------------------------\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 1. Load MNIST dataset\n",
    "# -------------------------------------------------------\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 2–4. Flatten, transpose, normalize training data\n",
    "# -------------------------------------------------------\n",
    "U = tf.reshape(x_train, (60000, 784))\n",
    "X = tf.transpose(U)\n",
    "X = tf.cast(X, tf.float32) / 255.0\n",
    "Y = tf.transpose(y_train)\n",
    "\n",
    "print(f\"X shape: {X.shape}, Y shape: {Y.shape}\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 6–8. Prepare test data\n",
    "# -------------------------------------------------------\n",
    "V = tf.reshape(x_test, (10000, 784))\n",
    "Xtest = tf.transpose(V)\n",
    "Xtest = tf.cast(Xtest, tf.float32) / 255.0\n",
    "Ytest = tf.transpose(y_test)\n",
    "\n",
    "print(f\"Xtest shape: {Xtest.shape}, Ytest shape: {Ytest.shape}\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 10. Display one training image\n",
    "# -------------------------------------------------------\n",
    "image_flat = X[:, 0]\n",
    "label = Y[0]\n",
    "image_2d = tf.reshape(image_flat, (28, 28))\n",
    "plt.imshow(image_2d.numpy(), cmap='gray')\n",
    "plt.title(f\"Label: {label.numpy()}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 11. Set hyperparameters\n",
    "# -------------------------------------------------------\n",
    "p = 10   # hidden layer neurons\n",
    "q = 10   # output layer neurons (digits 0–9)\n",
    "alpha = 0.01  # learning rate\n",
    "epochs = 1000\n",
    "\n",
    "print(f\"Hidden: {p}, Output: {q}, LR: {alpha}, Epochs: {epochs}\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 12–15. Initialize weights & biases\n",
    "# -------------------------------------------------------\n",
    "n = X.shape[0]  # features = 784\n",
    "m = X.shape[1]  # samples = 60000\n",
    "\n",
    "# Xavier initialization\n",
    "W1 = tf.Variable(tf.random.normal((p, n), mean=0.0, stddev=tf.sqrt(1.0 / tf.cast(n, tf.float32))))\n",
    "B1 = tf.Variable(tf.zeros((p, 1)))\n",
    "W2 = tf.Variable(tf.random.normal((q, p), mean=0.0, stddev=tf.sqrt(1.0 / tf.cast(p, tf.float32))))\n",
    "B2 = tf.Variable(tf.zeros((q, 1)))\n",
    "\n",
    "print(W1.shape, B1.shape, W2.shape, B2.shape)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 16. Manual Forward & Backward Propagation\n",
    "# -------------------------------------------------------\n",
    "def relu(Z):\n",
    "    return tf.maximum(0.0, Z)\n",
    "\n",
    "def relu_deriv(Z):\n",
    "    return tf.cast(Z > 0, tf.float32)\n",
    "\n",
    "def one_hot(Y, num_classes=10):\n",
    "    return tf.transpose(tf.one_hot(Y, num_classes))\n",
    "\n",
    "Y_oh = one_hot(Y, 10)\n",
    "Y = tf.cast(Y, tf.int64)   # ✅ Fix datatype issue once globally\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # Forward propagation\n",
    "    Z1 = tf.matmul(W1, X) + B1\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = tf.matmul(W2, A1) + B2\n",
    "    A2 = tf.nn.softmax(Z2, axis=0)\n",
    "\n",
    "    # Backward propagation\n",
    "    dZ2 = A2 - Y_oh\n",
    "    dW2 = (1 / m) * tf.matmul(dZ2, tf.transpose(A1))\n",
    "    dB2 = (1 / m) * tf.reduce_sum(dZ2, axis=1, keepdims=True)\n",
    "    dA1 = tf.matmul(tf.transpose(W2), dZ2)\n",
    "    dZ1 = dA1 * relu_deriv(Z1)\n",
    "    dW1 = (1 / m) * tf.matmul(dZ1, tf.transpose(X))\n",
    "    dB1 = (1 / m) * tf.reduce_sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    # Parameter update\n",
    "    W1.assign_sub(alpha * dW1)\n",
    "    B1.assign_sub(alpha * dB1)\n",
    "    W2.assign_sub(alpha * dW2)\n",
    "    B2.assign_sub(alpha * dB2)\n",
    "\n",
    "    # Monitor training progress\n",
    "    if epoch % 100 == 0 or epoch == 1:\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf.transpose(Y_oh), logits=tf.transpose(Z2)))\n",
    "        preds = tf.argmax(A2, axis=0)\n",
    "        acc = tf.reduce_mean(tf.cast(preds == Y, tf.float32)) * 100\n",
    "        print(f\"Epoch {epoch:4d} | Loss: {loss.numpy():.6f} | Accuracy: {acc.numpy():.2f}%\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 17. Automatic Differentiation using GradientTape (Demo)\n",
    "# -------------------------------------------------------\n",
    "X_demo = tf.random.normal((4, 10))\n",
    "Y_demo = tf.cast(tf.random.uniform((1, 10), maxval=2, dtype=tf.int32), tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random.normal((3, 4), stddev=0.01))\n",
    "B1 = tf.Variable(tf.zeros((3, 1)))\n",
    "W2 = tf.Variable(tf.random.normal((1, 3), stddev=0.01))\n",
    "B2 = tf.Variable(tf.zeros((1, 1)))\n",
    "\n",
    "for epoch in range(500):\n",
    "    with tf.GradientTape() as tape:\n",
    "        Z1 = tf.matmul(W1, X_demo) + B1\n",
    "        A1 = tf.nn.relu(Z1)\n",
    "        Z2 = tf.matmul(W2, A1) + B2\n",
    "        A2 = tf.sigmoid(Z2)\n",
    "        cost = -tf.reduce_mean(Y_demo * tf.math.log(A2 + 1e-8) + (1 - Y_demo) * tf.math.log(1 - A2 + 1e-8))\n",
    "    grads = tape.gradient(cost, [W1, B1, W2, B2])\n",
    "    for param, grad in zip([W1, B1, W2, B2], grads):\n",
    "        param.assign_sub(alpha * grad)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch:4d} | Cost: {cost.numpy():.6f}\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 18–19. Predicting on Test Set using Keras Model (for comparison)\n",
    "# -------------------------------------------------------\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "Y_train_onehot = tf.keras.utils.to_categorical(y_train, 10)\n",
    "Y_test_onehot = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(\"\\nTraining Keras model for comparison...\")\n",
    "model.fit(x_train.reshape(-1, 784) / 255.0, Y_train_onehot, epochs=5, batch_size=32, verbose=1)\n",
    "\n",
    "loss, accuracy = model.evaluate(x_test.reshape(-1, 784) / 255.0, Y_test_onehot, verbose=0)\n",
    "print(f\"\\n✅ Test Accuracy (Keras Model): {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8351fe71-d971-40cb-8526-ec41ac3146ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8b7008-f69c-4d10-911a-8a42cb0ba5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9af654-a42f-4d3e-b8b3-858da5072546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545cf8c6-54f7-4f5c-b876-baaa0155a85a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
